{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Phase 1 Notebook: `graph.py`\n",
        "\n",
        "Target file: `execution/langgraph/graph.py`\n",
        "\n",
        "Purpose: implement LangGraph node orchestration with schema validation, policy checks, duplicate-tool protection, and checkpointing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3-Layer Context\n",
        "\n",
        "- Layer 1 (Directive): this is the P1 orchestration centerpiece requested by `directives/phase1_langgraph.md`.\n",
        "- Layer 2 (Orchestration): defines node graph (`plan -> execute -> policy -> finalize`).\n",
        "- Layer 3 (Execution): node handlers call deterministic tools/checkpoint stores and only use LLM for planning output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "repo_root = /home/nir/dev/agent_phase0\n",
            "kernel_python = /home/nir/dev/agent_phase0/.venv/bin/python\n",
            "langgraph_available = True\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "import sys\n",
        "import os\n",
        "import importlib.util\n",
        "\n",
        "def bootstrap_repo_root() -> Path:\n",
        "    cwd = Path.cwd().resolve()\n",
        "    candidates = [cwd, *cwd.parents, Path('/home/nir/dev/agent_phase0')]\n",
        "    for candidate in candidates:\n",
        "        if (candidate / 'execution' / 'langgraph' / 'graph.py').exists():\n",
        "            if str(candidate) not in sys.path:\n",
        "                sys.path.insert(0, str(candidate))\n",
        "            return candidate\n",
        "    raise RuntimeError('Could not locate repo root for graph notebook.')\n",
        "\n",
        "repo_root = bootstrap_repo_root()\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv(repo_root / \".env\")\n",
        "print('P1_PROVIDER =', os.getenv('P1_PROVIDER', 'ollama'))\n",
        "print('repo_root =', repo_root)\n",
        "print('kernel_python =', sys.executable)\n",
        "if '/.venv/' not in sys.executable.replace('\\\\', '/'):\n",
        "    print('WARNING: kernel is not the project .venv interpreter.')\n",
        "\n",
        "LANGGRAPH_AVAILABLE = importlib.util.find_spec('langgraph') is not None\n",
        "print('langgraph_available =', LANGGRAPH_AVAILABLE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## P0 vs P1 (Orchestration Core)\n",
        "\n",
        "| Concern | Phase 0 (`orchestrator.py`) | Phase 1 (`graph.py`) | Why this matters |\n",
        "|---|---|---|---|\n",
        "| Control structure | manual loop with conditionals | explicit graph nodes and edges | clearer execution semantics and extension points |\n",
        "| State safety | assumes key presence in many spots | `ensure_state_defaults` at node boundaries | resilient against partial/serialized state |\n",
        "| Duplicate calls | hash tracking in state object | `seen_tool_signatures` guard with retry counter | prevents wasted loops and cost spikes |\n",
        "| Memoization policy | mostly prompt-driven | explicit policy node + bounded retries | deterministic reliability behavior |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Why this block exists: inspect graph structure\n",
        "\n",
        "Inspecting source ensures the compiled graph and node handlers match the intended P1 architecture before runtime tests."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    def _compile_graph(self):\n",
            "        if StateGraph is None:\n",
            "            raise RuntimeError(\n",
            "                \"langgraph is not installed. Add langgraph to requirements and install dependencies.\"\n",
            "            )\n",
            "\n",
            "        builder = StateGraph(RunState)\n",
            "        builder.add_node(\"plan\", self._plan_next_action)\n",
            "        builder.add_node(\"execute\", self._execute_action)\n",
            "        builder.add_node(\"policy\", self._enforce_memo_policy)\n",
            "        builder.add_node(\"finalize\", self._finalize)\n",
            "        builder.add_edge(START, \"plan\")\n",
            "        builder.add_conditional_edges(\n",
            "            \"plan\",\n",
            "            self._route_after_plan,\n",
            "            {\n",
            "                \"plan\": \"plan\",\n",
            "                \"execute\": \"execute\",\n",
            "                \"finish\": \"finalize\",\n",
            "            },\n",
            "        )\n",
            "        builder.add_edge(\"execute\", \"policy\")\n",
            "        builder.add_edge(\"policy\", \"plan\")\n",
            "        builder.add_edge(\"finalize\", END)\n",
            "        return builder.compile()\n",
            "\n",
            "    def _execute_action(self, state: RunState) -> RunState:\n",
            "        state = ensure_state_defaults(state, system_prompt=self.system_prompt)\n",
            "        action = state.get(\"pending_action\")\n",
            "        if not action:\n",
            "            return state\n",
            "\n",
            "        if action.get(\"action\") == \"finish\":\n",
            "            state[\"final_answer\"] = str(action.get(\"answer\", \"\"))\n",
            "            return state\n",
            "\n",
            "        tool_name = str(action.get(\"tool_name\", \"\"))\n",
            "        tool_args = dict(action.get(\"args\", {}))\n",
            "\n",
            "        if state[\"policy_flags\"].get(\"memo_required\") and tool_name != \"memoize\":\n",
            "            retry_count = int(state[\"retry_counts\"].get(\"memo_policy\", 0)) + 1\n",
            "            state[\"retry_counts\"][\"memo_policy\"] = retry_count\n",
            "            if retry_count > self.policy.max_policy_retries:\n",
            "                raise MemoizationPolicyViolation(\n",
            "                    \"Memoization required but model repeatedly skipped it.\"\n",
            "                )\n",
            "\n",
            "            required_key = str(state[\"policy_flags\"].get(\"memo_required_key\", \"\"))\n",
            "            reason = str(state[\"policy_flags\"].get(\"memo_required_reason\", \"\"))\n",
            "            state[\"messages\"].append(\n",
            "                {\n",
            "                    \"role\": \"system\",\n",
            "                    \"content\": (\n",
            "                        f\"Memoization required before proceeding ({reason}). \"\n",
            "                        f\"Call memoize now with key='{required_key}' and run_id='{state['run_id']}'.\"\n",
            "                    ),\n",
            "                }\n",
            "            )\n",
            "            state[\"pending_action\"] = None\n",
            "            self.checkpoint_store.save(\n",
            "                run_id=state[\"run_id\"],\n",
            "                step=state[\"step\"],\n",
            "                node_name=\"execute_policy_retry\",\n",
            "                state=state,\n",
            "            )\n",
            "            return state\n",
            "\n",
            "        if tool_name not in self.tools:\n",
            "            state[\"messages\"].append(\n",
            "                {\n",
            "                    \"role\": \"system\",\n",
            "                    \"content\": f\"Unknown tool '{tool_name}'. Use one of: {', '.join(self.tools.keys())}.\",\n",
            "                }\n",
            "            )\n",
            "            state[\"pending_action\"] = None\n",
            "            self.checkpoint_store.save(\n",
            "                run_id=state[\"run_id\"],\n",
            "                step=state[\"step\"],\n",
            "                node_name=\"execute_unknown_tool\",\n",
            "                state=state,\n",
            "            )\n",
            "            return state\n",
            "\n",
            "        if tool_name in {\"memoize\", \"retrieve_memo\"}:\n",
            "            tool_args.setdefault(\"run_id\", state[\"run_id\"])\n",
            "        if tool_name == \"memoize\":\n",
            "            tool_args.setdefault(\"step\", state[\"step\"])\n",
            "\n",
            "        signature = f\"{tool_name}:{json.dumps(tool_args, sort_keys=True, default=str)}\"\n",
            "        if signature in state[\"seen_tool_signatures\"]:\n",
            "            state[\"retry_counts\"][\"duplicate_tool\"] = int(state[\"retry_counts\"][\"duplicate_tool\"]) + 1\n",
            "            state[\"messages\"].append(\n",
            "                {\n",
            "                    \"role\": \"system\",\n",
            "                    \"content\": (\n",
            "                        f\"Duplicate tool call detected for '{tool_name}' with the same arguments. \"\n",
            "                        \"Do not repeat completed calls. Move to the next task or finish if done.\"\n",
            "                    ),\n",
            "                }\n",
            "            )\n",
            "            state[\"pending_action\"] = None\n",
            "            self.checkpoint_store.save(\n",
            "                run_id=state[\"run_id\"],\n",
            "                step=state[\"step\"],\n",
            "                node_name=\"execute_duplicate_tool\",\n",
            "                state=state,\n",
            "            )\n",
            "            return state\n",
            "        state[\"seen_tool_signatures\"].append(signature)\n",
            "\n",
            "        tool_result = self.tools[tool_name].execute(tool_args)\n",
            "        state[\"tool_call_counts\"][tool_name] = int(state[\"tool_call_counts\"].get(tool_name, 0)) + 1\n",
            "        call_number = len(state[\"tool_history\"]) + 1\n",
            "        state[\"tool_history\"].append(\n",
            "            {\n",
            "                \"call\": call_number,\n",
            "                \"tool\": tool_name,\n",
            "                \"args\": tool_args,\n",
            "                \"result\": tool_result,\n",
            "            }\n",
            "        )\n",
            "        state[\"messages\"].append(\n",
            "            {\n",
            "                \"role\": \"system\",\n",
            "                \"content\": (\n",
            "                    f\"TOOL_RESULT #{call_number} ({tool_name}): {json.dumps(tool_result)}\\n\"\n",
            "                    \"Continue with the next task or finish when all tasks are complete.\"\n",
            "                ),\n",
            "            }\n",
            "        )\n",
            "\n",
            "        if tool_name == \"memoize\" and \"value_hash\" in tool_result:\n",
            "            state[\"memo_events\"].append(\n",
            "                MemoEvent(\n",
            "                    key=str(tool_result.get(\"key\", \"\")),\n",
            "                    namespace=str(tool_result.get(\"namespace\", \"run\")),\n",
            "                    source_tool=str(tool_args.get(\"source_tool\", \"memoize\")),\n",
            "                    step=state[\"step\"],\n",
            "                    value_hash=str(tool_result[\"value_hash\"]),\n",
            "                    created_at=utc_now_iso(),\n",
            "                )\n",
            "            )\n",
            "            state[\"policy_flags\"][\"memo_required\"] = False\n",
            "            state[\"policy_flags\"][\"memo_required_key\"] = \"\"\n",
            "            state[\"policy_flags\"][\"memo_required_reason\"] = \"\"\n",
            "            state[\"retry_counts\"][\"memo_policy\"] = 0\n",
            "\n",
            "        state[\"policy_flags\"][\"last_tool_name\"] = tool_name\n",
            "        state[\"policy_flags\"][\"last_tool_args\"] = tool_args\n",
            "        state[\"policy_flags\"][\"last_tool_result\"] = tool_result\n",
            "        state[\"pending_action\"] = None\n",
            "        self.checkpoint_store.save(\n",
            "            run_id=state[\"run_id\"],\n",
            "            step=state[\"step\"],\n",
            "            node_name=\"execute\",\n",
            "            state=state,\n",
            "        )\n",
            "        return state\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import inspect\n",
        "from execution.langgraph.graph import LangGraphOrchestrator\n",
        "\n",
        "print(inspect.getsource(LangGraphOrchestrator._compile_graph))\n",
        "print(inspect.getsource(LangGraphOrchestrator._execute_action))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Why this block exists: offline scripted run\n",
        "\n",
        "We use scripted model outputs to test orchestration deterministically. This avoids network dependence and isolates control-logic behavior."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "done\n",
            "{'invalid_json': 0, 'memo_policy': 0, 'duplicate_tool': 1}\n",
            "{'write_file': 1, 'memoize': 1, 'sort_array': 1}\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "from execution.langgraph.memo_store import SQLiteMemoStore\n",
        "from execution.langgraph.checkpoint_store import SQLiteCheckpointStore\n",
        "from execution.langgraph.policy import MemoizationPolicy\n",
        "from execution.langgraph.graph import LangGraphOrchestrator\n",
        "\n",
        "class ScriptedProvider:\n",
        "    def __init__(self, responses):\n",
        "        self.responses = [json.dumps(item) for item in responses]\n",
        "        self.index = 0\n",
        "\n",
        "    def generate(self, messages):\n",
        "        if self.index < len(self.responses):\n",
        "            value = self.responses[self.index]\n",
        "            self.index += 1\n",
        "            return value\n",
        "        return self.responses[-1]\n",
        "\n",
        "if LANGGRAPH_AVAILABLE:\n",
        "    provider = ScriptedProvider([\n",
        "        {'action': 'tool', 'tool_name': 'write_file', 'args': {'path': 'fib.txt', 'content': ','.join(str(i) for i in range(150))}},\n",
        "        {'action': 'tool', 'tool_name': 'memoize', 'args': {'key': 'write_file:fib.txt', 'value': {'ok': True}, 'source_tool': 'write_file'}},\n",
        "        {'action': 'tool', 'tool_name': 'sort_array', 'args': {'items': [3, 2, 1], 'order': 'asc'}},\n",
        "        {'action': 'tool', 'tool_name': 'sort_array', 'args': {'items': [3, 2, 1], 'order': 'asc'}},\n",
        "        {'action': 'finish', 'answer': 'done'}\n",
        "    ])\n",
        "    orchestrator = LangGraphOrchestrator(\n",
        "        provider=provider,\n",
        "        memo_store=SQLiteMemoStore('.tmp/notebook_demo_graph_memo.db'),\n",
        "        checkpoint_store=SQLiteCheckpointStore('.tmp/notebook_demo_graph_ckpt.db'),\n",
        "        policy=MemoizationPolicy(max_policy_retries=2),\n",
        "        max_steps=30,\n",
        "    )\n",
        "    result = orchestrator.run('offline graph demo')\n",
        "    print(result['answer'])\n",
        "    print(result['state']['retry_counts'])\n",
        "    print(result['state']['tool_call_counts'])\n",
        "else:\n",
        "    result = None\n",
        "    print('Install langgraph to run this runtime demo.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if LANGGRAPH_AVAILABLE:\n",
        "    assert result['answer'] == 'done'\n",
        "    assert result['state']['retry_counts']['duplicate_tool'] >= 1\n",
        "    assert 'write_file' in result['state']['tool_call_counts']\n",
        "    print('graph assertions passed')\n",
        "else:\n",
        "    print('Skipped assertions because langgraph is not installed in this kernel.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Takeaways\n",
        "\n",
        "- P1 orchestration is graph-native, not only loop-native.\n",
        "- Duplicate tool call protection and memo policy enforcement are explicit runtime behaviors.\n",
        "- Node-level checkpoints give recovery and audit leverage absent in P0.\n",
        "- Next notebook sequence complete. Return to index notebook for cross-links."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}